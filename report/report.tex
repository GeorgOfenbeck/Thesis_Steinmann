\documentclass[a4paper,12pt]{article}
\usepackage[colorlinks,bookmarks,pagebackref]{hyperref}
\usepackage{graphicx} 

\newcommand{\umlDiagram}[1]{\begin{center}\includegraphics[width=\textwidth]{../../umlDiagrams/#1.png}\end{center}}

\newcommand{\umlFloat}[2]{
\begin{figure}[tbh]
\umlDiagram{#1}
\caption{#2}
\label{#1}
\end{figure}
}

\newcommand{\umlFloatCap}[3]{
\begin{figure}[tbh]
\umlDiagram{#1}
\caption[#2]{#3}
\label{#1}
\end{figure}
}
\newcommand{\umlRef}[1]{\autoref{#1}}


\title{Applying the Roofline Model}
\author{Ruedi Steinmann}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
This is the paper's abstract \ldots
\end{abstract}

\tableofcontents

\section{Introduction}
In this thesis, we would like to analyze a substantial amount of diverse code using the roofline model presented in \cite{Roofline}. The code can come either in the form of a relatively isolated routine, typically containing a single kernel, or in the form of a larger program, containing multiple different kernels.

While routines are typically treated as atomic unit, it is desireable to split the larger program into it's different algorithms and do the analysis for each algorithm separately. In the rest of this paper, we will use the term kernel for a routine or part of a program which is analyzed on it's own.

To obtain the peak performance lines for the roofline model, we need to run various micro benchmarks. To get the data points for a kernel, we need to measure the performance and the operational intensity. 

Performance is defined as amount of work per unit of time. The amount of work and how it is defined is determined by the actual kernel and does not need to be measured directly by the measurement tool. The time required to do the work has to be measured.

Operational intensity is defined as operations per byte of data traffic. Since the operational intensity cannot be measured directly, we have to measure the operation count and the data traffic. Depending on the problem, different definitions of operation and data traffic make sense.

An operation could be a floating point operation, resulting int the well known "flops" unit, either single or double precision. But an operation could as well be defined as machine instruction, integer operation or others.

The point where data traffic is measured is typically between the last level of the processor cache and the DRAM, but it could be measured as well between the different cache levels or between L1 cache and processor.

The microbenchmarks are typically designed to either transfer as much data per unit of time or to execute as may operations per unit of time. Thus the measurement capabilities needed to evaluate the actual problems can be reused for the benchmarks. 

In summary, we need to measure the following quantities:
\begin{itemize}
\item execution time
\item memory traffic
\item operation count
\end{itemize}

On current processors, measuring these quantities should be possible. For the execution time either the cycle counter or the system timer can be used. The memory traffic can be determined using the performance counters for counting cach misses and write back operations. (what about not temporal stores?) Measuring the operation count depends heavily on the definition of operation, but is typically measurable with the performance counters, too.

While each of the measurements above has it's own subtleties, there are some effects affecting all of the above measurements, which we will discuss in the following sections.

\subsection{Context Switches}

Unless a special operating system is used, we have to deal with context switches during measurement. On current operating systems, a context switch typically occurs every 10ms due to the timer interrupt. Following the lines of \cite{ComSysProgPersp}, there are two ways to deal with them:

If the execution time of the kernel is small, the operating system will eventually execute the whole kernel without interruption. This can be exploited using the best k measurement scheme. The kernel is repeatedly executed until the k measurements with the smallest execution times show a variation below a certain threshold. These executions were apparently not affected by a context switch, since a context switch would have increased exection time. The HW\_INT\_RCV performance counter could possibly be used as well to detect context switches.

If a single execution of the kernel takes longer than the period of time between two timer interrupts, it will always be affected by a context switch. In this case, the proposed solution is to execute the kernel in a loop until many context switches occurred. The effect of the context switches can be compensated for by reducing the measured time be a certain factor. The factor depends on the actual system.

\subsection{Cache}
Specially for short running kernels, the inital state of the cache can have a big impact on the memory traffic and execution time. [?] The impact can be controlled by making sure the caches are either warm or cold.

To get a cold cache, a memory block with a larger size than the last level cache should be accessed directly before executing the kernel. This causes all cache lines containig data of the working set to be evicted. In a similar manner, enough code should be executed to clear the L1 code cache.

To get a warm cache, the kernel is usually executed once before starting the measurement. This causes the working set to be loaded in the caches, if it fits, and the code to be in the cache as well.

\subsection{System Load}
Specially if the measurement includes context switches, the system load has a big impact on the measurement result. But due to caching effects, even the k best measurement scheme might be affected by the system load. Since we can controll the system the measurements are perfomed on, we can control system load. But none the less, it should be recorded along with the measurement, in case something goes wrong with the measurement system setup.

\subsection{Multi Threading}
Our kernels and benchmarks will use multi threading. This has to be supported by the measurement tool. Since some caches as well as part of the memory bandwith might be shared among different cores, multithreading can have various effects on the amount of transferred memory and the available bandwith.

In case of hyper threading, some functional units of a processor core are shared among two threads. This influences the peak performance of the core.

It is possible that the operating system moves a thread from one core to another. Since the overhead of a switching the core is large, it is generally avoided by the scheduler of the operating system. But it can occur, and we have to be prepared for it.

\section{Measurement Tool Architecture}
Performing measurements requires a kernel, a measurer and a measurement scheme. The kernel contains the code to be measured and can be either custom code or a wrapper around existing code. The measurer is responsible for the actual measuring and produces an output. The measurement scheme finally controls the kernel and the measurer. The three parts together form the Measuring Core.

We decided that the Measuring Core is implemented in the C++ language. To simplify development and maintenance, we tried to keep the amount of C++ code as small as possible. The rest is written in Java.

To allow all possible optimizations, it must be possible to pass compile time arguments to the Measuring Core and recompile for each measuring.

\subsection{Component Collaboration}
The tool consists of two main components: The Measuring Core, which performs the actual measurements, and the Measurement Driver, which controls the core.

A measurement is controlled by a measurement specific routine (one per measurement), which iterates through all parameter points to be examined, compiles and starts the Measuring Core and processes the results. This should result in straight forward code for controlling the measurements and, since the control code is written in Java, a minimal amount of new concepts has to be learned.

During the development of measurement control routines, it is expected that many changes do not affect the parameter points. To speed up repeated measurements after changes to the measurement driver, the measurement results are cached. Thus, as long as the measurement parameters are not changed, the measurement does not need to be repeated.

The measurement tool is used to generate and display measurement results. Often, the measurement results lead to changes to the tool itself. Thus, switches between using the tool and developing the tool are frequent. To support these switches, a frontend program is provided. It compiles the measurement driver and executes it. It can be started using a shell script called "rmt", which has to be placed manually in a directory in the shell path. The result files of a measurement are placed in the current working directory.

\umlDiagram{ToolComponents}

Data transfer between the measuring core and the measurement driver is archieved using serialized objects stored in files. The classes of this Shared DOM are shown in the following diagram:

\umlDiagram{MultiLanguageClasses}

Each MeasurementDescription describes how to perform a single measurement. It contains a MeasurementSchemeDescription, a KernelDescription and a MeasurerDescription. Each description contains all information required to set up the respective part of the Measuring Core (type, parameters, \ldots).

We intentionally directly describe Measuring Core parts in the SharedDOM. This allows the MeasuringCore to directly use the information contained therein and thus helps to keep the core simple.

\subsection{Multi Language Infrastructure}
All classes in the SharedDOM are used by components written in Java. But some of them are also used by the Measuring Core, which is written in C++. To avoid having to manually synchronize two versions of the same classes, the source code for the C++ and the Java implementation is generated from an XML definition by the Multi Language Code Generator. The XML definition contains field definitions only, no code. If class specific code is needed, it has to be implemented separately for each language and merged with the field definitions using inheritance.

Along with the source code for each class, the implementation of the MultiLanguageSerializationService is generated for both languages. This service allows to serialize to and deserialize from a simple text based serialization format. It supports the following primitive types:
\begin{itemize}
\item double
\item integer
\item long integer
\item boolean
\item string
\end{itemize}

References to other multi language classes are supported. The serializer does not recognize if the same object can be reached multiple times within the same object graph. Each time it encounters an object, the object is serialized instead of referencing the previous serialization.

Lists containing one of the supported primitive types as well as containing references to multi language classes are supported.

The XML class representation is parsed using a serialization library called XStream. XStream maps classes to an XML representation. The serialized classes are shown in \umlRef{MultiLanguageClassDefinition}.

\umlFloat{MultiLanguageClassDefinition}{Elements representing a multi language class definition}

The following is an example of a class definition:
\begin{verbatim}
<?xml version="1.0" encoding="UTF-8"?>
<class name="MultiLanguageTestClass" 
  cBaseType="MultiLanguageObjectBase"
  javaBaseType=""
  comment="Multi Language Class used for unit tests">

  <field 
    name="longField" 
    type="long" 
    comment="test field with type 'long'"/>
  <list  
    name="referenceList" 
    type="MultiLanguageTestClass" 
    comment="list referencing full classes"/>
  <field 
    name="referenceField" 
    type="MultiLanguageTestClass" 
    comment="field referencing another class"/>
</class>
\end{verbatim}

After the definitions are loaded, Velocity templates are used to generate all source code.

The class definitions and the generated code is located in the Multi Language Classes project. The generated java code is linked by the Shared DOM project. The generated C code is linked by the Measuring Core. The following Diagram shows the build dependencies:

\umlDiagram{BuildDependencies}

\subsection{How To}
\subsubsection{Install}
see INSTALL file in tool directory

\subsubsection{Create New Kernels}
\begin{itemize}
\item create the xml description of your kernel description in multiLanguageClasses/definitions/kernels
\item run "rmt help" to generate the multi language code from you description
\item create your kernel implementation in measuringCore/kernels. Subclass "Kernel", parameterized to the description class you've created. Implement "initialize()", "run()" and "dispose()".
\item register your kernel class. In the cpp file of your kernel implementation, include "typeRegistry/TypeRegisterer.h" and instantiate a static global variable of type "TypeRegisterer", parameterized to your kernel implementation.
\item use your kernel from a measurement
\end{itemize}

\subsubsection{Create New Measurement}
\begin{itemize}
\item create new class in measurementDriver/measurements
\item implement IMeasurement
\end{itemize}

\subsubsection{Add Configuration Key}
The configuration is used to set various flags in the measurement driver.
\begin{itemize}
\item add public static field of type ConfigurationKey to any class within the measurement driver.
\end{itemize}

\subsection{Measurement Driver}

\subsection{Measuring Core}
\umlFloat{CentralClasses}{Central classes of the measuring core}
The central classes of the Measuring Core are the measurement scheme, the kernel and the measurer. (\umlRef{CentralComponents}) The MeasurementScheme has template arguments for the kernel and the measurer type. The scheme contains nested instances of the kernel and the measurer. This disables polymorphic calls and allows the compiler to fully optimize the measure function of the measurer, including inlining methods of the kernel and the measurer.

\subsubsection{Type Registry}
The Measuring Core receives kernel, measurement scheme and measurer descriptions and needs to instantiate the corresponding kernels, measurement schemes and measurers. Conceptually, each description class is associated to exactly one object class. The description describes instances of the associated object class. In code, the realtionships are represented using typedefs and they are checked using concept checking (\cite{siek01_concept_check}).

The object classes are grouped by base classes. The TypeRegistry templated class is instantiated for each base class. For each object class a TypeRegisterer is instantiated as static global variable (static means only visible in the file that defines the variable). The constructor of the TypeRegisterer creates a TypeRegistryEntry for the object class and adds it to the corresponding TypeRegistry instantiation.

\umlDiagram{TypeRegistry}

The MeasurerScheme has template type parameters for the measurer and the kernel it operates on. This allows the compiler to do optimizations, which is important for small kernels. The type registry supports this by accepting a number of arguments along with the description. The arguments sent to the TypeRegistryEntries for matching. The matching is based on the dynamic type of the provided arguments and the TArgs type arguments of the TypeRegistryEntry. When creating an object, the arguments are passed to the object constructor.

The methods on the TypeRegistry have type arguments. These will be set to the base classes of the arguments. But the important information is the actual type of the arguments. Therefore the arguments are packed into a vector and sent to the TypeRegistryEntries which use dynamic\_cast to determine if the arguments match the type arguments. Dynamic cast needs pointers to a polymorphic class. Since void pointers are not polymorphic, pointers to PolymorphicBase are used.

The code makes use of variadic templates (\cite{Gregor06:variadics_rev_3}).

\section{Measuring Execution Time}
\begin{itemize}
\item 0x40000000   UNHALTED\_CORE\_CYCLES 30Ah CPU\_CLK\_UNHALTED.CORE
\item 0x40000025   UNHALTED\_REFERENCE\_CYCLES 30Bh CPU\_CLK\_UNHALTED.REF
\item 0x400000ad   THERMAL\_TRIP 3Bh C0h 
\item 0x400000ae   CPU\_CLK\_UNHALTED
\item 0x400001a9   ix86arch::UNHALTED\_CORE\_CYCLES
\item 0x400001aa   ix86arch::INSTRUCTION\_RETIRED
\item 0x400001ab   ix86arch::UNHALTED\_REFERENCE\_CYCLES 
\end{itemize}
\subsection{Frequency Scaling}
The core frequency is not constant in current processors. Since the memory latencies and throughputs do not scale with the core freqency, a lower core freqency will generally cause a higher percentage of the peak performance to be reached by the kernel.

It is difficult to control the core frequency. But the frequency should at least be recorded along with the measurement. If the frequency changes during the measurement, this should be recored as well. The other option is to disable frequency scaling completely.

\section{Measuring Memory Traffic}
\begin{itemize}
\item 0x40000027   LLC\_MISSES
\item 0x40000040   SSE\_PRE\_EXEC 07h03h SSE\_PRE\_EXEC.L2
\item 0x40000059   L2\_DBUS\_BUSY\_RD
\item 0x4000005c   L2\_LINES\_IN  24h
\item 0x4000006a   L2\_M\_LINES\_OUT  27h
\item 0x400000cb   SSE\_PRE\_MISS 4Bh 00h/01h/02h
\item 62h BUS\_DRDY\_CLOCKS
\end{itemize}


\section{Mesuring Operation Count}
\begin{itemize}
\item 0x40000156   SIMD\_UOP\_TYPE\_EXEC B3h 01h/20h
\end{itemize}


\listoffigures

\bibliographystyle{abbrv}
\bibliography{../report.bib}

\end{document}
