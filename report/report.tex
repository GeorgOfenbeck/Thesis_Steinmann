\documentclass[a4paper,12pt]{article}
%\usepackage{../stringstrings}
\usepackage{makeidx}

\usepackage[colorlinks,bookmarks,pagebackref]{hyperref}
\usepackage{graphicx} 

\usepackage{../multind}
\makeindex{referencedFiles}

\newcommand{\umlDiagram}[1]{\begin{center}\includegraphics[width=\textwidth]{uml/#1.png}\end{center}}

%\newcommand{\file}[1]{\marginpar{\footnotesize \convertword{#1}{/}{/ }}\index{referencedFiles}{\convertword{#1}{\-}{}@\convertword{#1}{/}{/ }}}
\newcommand{\file}[1]{}

\newcommand{\umlFloat}[2]{
\begin{figure}[tbh]
\umlDiagram{#1}
\caption{#2}
\label{#1}
\end{figure}
}

\newcommand{\umlFloatCap}[3]{
\begin{figure}[tbh]
\umlDiagram{#1}
\caption[#2]{#3}
\label{#1}
\end{figure}
}
\newcommand{\umlRef}[1]{\autoref{#1}}


\title{Applying the Roofline Model}
\author{Ruedi Steinmann}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
This is the paper's abstract \ldots
\end{abstract}

\tableofcontents

\section{Introduction}
In this thesis, we would like to analyze a substantial amount of diverse code using the roofline model presented in \cite{Roofline}. The code can come either in the form of a relatively isolated routine, typically containing a single kernel, or in the form of a larger program, containing multiple different kernels.

While routines are treated as atomic unit, it is desireable to split the larger program into it's different algorithms and do the analysis for each algorithm separately. In the rest of this paper, we will use the term kernel for a routine or part of a program which is analyzed on it's own.

To obtain the peak performance lines for the roofline model, we need to run micro benchmarks. To get the data points for a kernel, we need to measure the performance and the operational intensity. 

Performance is defined as amount of work per unit of time. The amount of work and how it is defined is determined by the actual kernel and may not be need to be measured directly by the measurement tool. The time required to do the work has to be measured.

Operational intensity is defined as operations per byte of data traffic. Since the operational intensity cannot be measured directly, we have to measure the operation count and the data traffic. Depending on the problem, different definitions of operation and data traffic make sense.

An operation could be a floating point operation, resulting int the well known "flops" unit, either single or double precision. But an operation could as well be defined as machine instruction, integer operation or others.

The point where data traffic is measured is typically between the last level of the processor cache and the DRAM, but it could be measured as well between the different cache levels or between L1 cache and processor.

The microbenchmarks are typically designed to either transfer as much data per unit of time or to execute as may operations per unit of time. Thus the measurement capabilities needed to evaluate the actual problems can be reused for the benchmarks. 

In summary, we need to measure the following quantities:
\begin{itemize}
\item execution time
\item memory traffic
\item operation count
\end{itemize}

On current processors, measuring these quantities should be possible. For the execution time either the cycle counter or the system timer can be used. The memory traffic can be determined using the performance counters for counting cach misses and write back operations. (what about not temporal stores?) Measuring the operation count depends heavily on the definition of operation, but is typically measurable with the performance counters, too.

While each of the measurements above has it's own subtleties, there are some effects affecting all of the above measurements, which we will discuss in the following sections.

\subsection{Context Switches}

Unless a special operating system is used, we have to deal with context switches during measurement. On current operating systems, a context switch typically occurs every 10ms due to the timer interrupt. Following the lines of \cite{ComSysProgPersp}, there are two ways to deal with them:

If the execution time of the kernel is small, the operating system will eventually execute the whole kernel without interruption. This can be exploited using the best k measurement scheme. The kernel is repeatedly executed until the k measurements with the smallest execution times show a variation below a certain threshold. These executions were apparently not affected by a context switch, since a context switch would have increased exection time. The HW\_INT\_RCV performance counter could possibly be used as well to detect context switches.

If a single execution of the kernel takes longer than the period of time between two timer interrupts, it will always be affected by a context switch. In this case, the proposed solution is to execute the kernel in a loop until many context switches occurred. The effect of the context switches can be compensated for by reducing the measured time be a certain factor. The factor depends on the actual system.

\subsection{Cache}
Specially for short running kernels, the inital state of the cache can have a big impact on the memory traffic and execution time. [?] The impact can be controlled by making sure the caches are either warm or cold.

To get a cold cache, a memory block with a larger size than the last level cache should be accessed directly before executing the kernel. This causes all cache lines containig data of the working set to be evicted. In a similar manner, enough code should be executed to clear the L1 code cache.

To get a warm cache, the kernel is usually executed once before starting the measurement. This causes the working set to be loaded in the caches, if it fits, and the code to be in the cache as well.

\subsection{System Load}
Specially if the measurement includes context switches, the system load has a big impact on the measurement result. But due to caching effects, even the k best measurement scheme might be affected by the system load. Since we can controll the system the measurements are perfomed on, we can control system load. But none the less, it should be recorded along with the measurement, in case something goes wrong with the measurement system setup.

\subsection{Multi Threading}
Our kernels and benchmarks will use multi threading. This has to be supported by the measurement tool. Since some caches as well as part of the memory bandwith might be shared among different cores, multithreading can have various effects on the amount of transferred memory and the available bandwith.

In case of hyper threading, some functional units of a processor core are shared among two threads. This influences the peak performance of the core.

It is possible that the operating system moves a thread from one core to another. Since the overhead of a switching the core is large, it is generally avoided by the scheduler of the operating system. But it can occur, and we have to be prepared for it.

\section{Measurement Tool Architecture}
Performing measurements requires a kernel, a measurer and a measurement scheme. The kernel contains the code to be measured and can be either custom code or a wrapper around existing code. The measurer is responsible for the actual measuring and produces an output. The measurement scheme finally controls the kernel and the measurer. The three parts together form the Measuring Core.

We decided that the Measuring Core should be implemented in the C++ language. To simplify development and maintenance, we tried to keep the amount of C++ code as small as possible. The rest is written in Java.

To allow all possible optimizations, it must be possible to pass compile time arguments to the Measuring Core and recompile for each measurement.

\subsection{Component Collaboration}
The tool consists of two main components: The Measuring Core, which performs the actual measurements, and the Measurement Driver, which controls the core.

A measurement is controlled by a measurement specific routine (one per measurement), which iterates through all parameter points to be examined, compiles and starts the Measuring Core and processes the results. This should result in straight forward code for controlling the measurements and, since the control code is written in Java, a minimal amount of new concepts has to be learned.

During the development of measurement control routines, it is expected that many changes do not affect the parameter points. To speed up repeated measurements after changes to the measurement driver, the measurement results are cached. Thus, as long as the measurement parameters are not changed, the measurement does not need to be repeated.

The measurement tool is used to generate and display measurement results. Often, the measurement results lead to changes to the tool itself. Thus, switches between using the tool and developing the tool are frequent. To support these switches, a frontend program is provided. It compiles the measurement driver and executes it. It can be started using a shell script called "rot". The result files of a measurement are placed in the current working directory.

\umlDiagram{ToolComponents}

Data transfer between the measuring core and the measurement driver is archieved using serialized objects stored in files. The classes of this Shared DOM are shown in the following diagram:

\umlDiagram{MultiLanguageClasses}

Each MeasurementDescription describes how to perform a measurement. It contains a MeasurementSchemeDescription, a KernelDescription and a MeasurerDescription. Each description contains all information required to set up the respective part of the Measuring Core (type, parameters, \ldots).

We intentionally directly describe Measuring Core parts in the multi language classes. This allows the MeasuringCore to directly use the information contained therein and thus helps to keep the core simple.

\subsection{Multi Language Infrastructure}
The multi language classes are used from both C++ and Java. To avoid having to manually synchronize two versions of the same class, the source code for the C++ and the Java implementation is generated from an XML definition by the Multi Language Code Generator. The XML definition contains class and field definitions only, no code. If class specific code is needed, it has to be implemented separately for each language and merged with the field definitions using inheritance.

The multi language class definitions, written in XML, are parsed using a serialization library called XStream. XStream maps classes to an XML representation. The classes used to define the multi language classes are shown in \umlRef{MultiLanguageClassDefinition}.

\umlFloat{MultiLanguageClassDefinition}{Classes representing a multi language class definition}

The following is an example of a class definition:
\begin{verbatim}
<?xml version="1.0" encoding="UTF-8"?>
<class name="MultiLanguageTestClass" 
  cBaseType="MultiLanguageObjectBase"
  javaBaseType=""
  comment="Multi Language Class used for unit tests">

  <field 
    name="longField" 
    type="long" 
    comment="test field with type 'long'"/>
  <list  
    name="referenceList" 
    type="MultiLanguageTestClass" 
    comment="list referencing full classes"/>
  <field 
    name="referenceField" 
    type="MultiLanguageTestClass" 
    comment="field referencing another class"/>
</class>
\end{verbatim}

After the definitions are loaded, Velocity templates are used to generate all source code.

A normal class has a C and a Java base type. The C base type has to directly or inderectly inherit from MultiLanguageObjectBase, which is a polymorphic class. This allows to use the RTTI (RunTime Type Information). Java base types have no such constraint (due to the implicit common base class Object). The base types are just included in the generated source code, but have no other effect on the code generation.

A derived class names another multi language class as base type. The C and Java base types are set to that class. The fields of the base class are included in the serialization process. If just the C and Java base types would be set to the multi language class used as base class, the generated class would still derive from the base class, but the fields of the base class would not be included in the serialization process.

The class definitions and the generated code is located in the Multi Language Classes project. The generated java code is linked by the Measurement Driver project. The generated C code is linked by the Measuring Core. The following Diagram shows these dependencies:

\umlDiagram{CodeGenerationDependencies}

\subsubsection{Serialization and Deserialization}
Along with the source code for each class, a service serializing and deserializing multi language objects to/from a simple text based format is generated for both languages. It supports the following primitive types:
\begin{itemize}
\item double
\item integer
\item long integer
\item boolean
\item string
\end{itemize}

References to other multi language classes are supported. The serializer does not recognize if the same object can be reached multiple times within the same object graph. Each time it encounters an object, the object is serialized instead of referencing the previous serialization.

Lists containing one of the supported primitive types as well as containing references to multi language classes are supported.

The service implementations for both languages follow the same structure. Each has two methods, one for serialization and one for deserialization. 

The serialization method receives an object and an output stream. The  method body contains an if for each known serializable class, which checks if the class of the object received is equal to the serializable class. If true, the value of all fields of the class and it's base classes get serialized. For references, the  serialization method is called recursively with the same output stream and the  referenced object as parameters.

The deserialization method works analogous to the serialization method. It receives an input stream. The method body contains an if for each known serializable class, which checks if the next line of the input names  the serializable class. If true, a new instance of the class is created and the value of all fields are read from the input and set on the created instance, including all fields declared in a base class. If a reference is encountered, the deserialization method is called recursively with the same input, and the returned instance is used as field value.

\subsection{How To}
\subsubsection{Install}
see INSTALL file in tool directory

\subsubsection{Create New Kernels}
\begin{itemize}
\item create the xml description of your kernel description in multiLanguageClasses/definitions/kernels
\item run "rmt help" to generate the multi language code from you description
\item create your kernel implementation in measuringCore/kernels. Subclass "Kernel", parameterized to the description class you've created. Implement "initialize()", "run()" and "dispose()".
\item register your kernel class. In the cpp file of your kernel implementation, include "typeRegistry/TypeRegisterer.h" and instantiate a static global variable of type "TypeRegisterer", parameterized to your kernel implementation.
\item use your kernel from a measurement
\end{itemize}

\subsubsection{Create New Measurement}
\begin{itemize}
\item create new class in measurementDriver/measurements
\item implement IMeasurement
\end{itemize}

\subsubsection{Add Configuration Key}
The configuration is used to set various flags in the measurement driver.
\begin{itemize}
\item add public static field of type ConfigurationKey to any class within the measurement driver.
\end{itemize}

\subsubsection{Generate Annotated Assembly}
\begin{itemize}
\item in Eclipse, hit build (Ctrl+B)
\item change the kernel header file (make it recompile)
\item build again
\item from the console window, copy the compiler invocation for MeasurementSchemeRegistration.cpp
\item open a terminal and go to tool/measuringCore/Debug.
\item paste the compiler invocation
\item insert "-Wa,-ahl=ass.s", check optimization flags
\item issue command
\item the annotated assembly code can be found in tool/measuringCore/Debug/ass.s
\item open the annotated assembly code in Eclipse
\end{itemize}

\subsection{Measurement Driver}
It was tried to follow best engineering practices for the design of the measurement driver. Unit tests, mocks, and dependency injection is used. Furthermore, a domain model (DOM) and stateless services are used as described in \cite{evans2004domain}. Describing all these concepts lies beyond the scope of this report. It is assumed that the reader has a basic understanding of the named concepts.

\subsubsection{Configuration}
The design goal was to create a configuration system which
\begin{itemize}
\item allows to set configuration flags from the command line and from configuration files
\item can manage some form of comment for the flags
\item makes the available flags transparent
\item supports user specific configuration
\end{itemize}

\file{measurementDriver/src/ch/ethz/ruediste/roofline/measurementDriver/ConfigurationKey.java}
The central class of our solution is the configuration key. A configuration key contains a string key which identifies the configuration flag it represents. In addition, it contains a description and the default value of the flag. It has a template parameter which defines the data type of the flag. This removes the necessity to use type casts when reading configuration flags. Configuration keys should be stored in public static variables. The help command scans all classes of the measurement driver for such configuration keys and prints the key string and the description. After the configuration is loaded, it is checked if a configuration key is defined for each configuration flag specified. If a configuration key is missing (or more likely, a configuration flag has been misspelled in the configuration) an error is generated.

The following paragraphs describe the sources of configuration flag definitions in order of decreasing precedence. 

The command line is scanned for arguments starting with a dash. Such arguments are expected to be in the form of "-$<$flag key$>$=$<$value$>$" and specifies that the configuration with the specified flag key should have the specified value. Configuration flag definitions on the command line have highest precedence.

Next come two configuration files. They both have the same format: each line consists of the flag key, followed by an equal sign and the flag value. 

The first file is the user configuration file. By default it is located under \textasciitilde/.roofline/config, but this can be changed using the "userConfigFile" configuration flag, in particular by overwriting the flag on the command line.

The second file is the default configuration. It is located in the source code of the measurement driver, and can be loaded from the classpath. It contains some placeholders, which are expanded during the build process.

Finally, the flag definitions with lowest precedence are the default values given in the configuration keys.

\subsection{Measuring Core}
\umlFloat{CentralClasses}{Central classes of the measuring core}
The central classes of the Measuring Core are the measurement scheme, the kernel and the measurer. (\umlRef{CentralClasses}) The MeasurementScheme has template arguments for the kernel and the measurer type. The scheme contains nested instances of the kernel and the measurer. This avoids polymorphic calls and allows the compiler to fully optimize the measure function of the measurer, including inlining methods of the kernel and the measurer.

\subsubsection{Building}
Each measurement can be performed with different compiler optimization flags and macro definitions. Therefore, the measuring core has to be rebuilt for each measurement, which makes rebuilding the measuring core a frequent operation. It should therefore be as fast as possible. This is archieved by carefully tracking all build dependencies and by using ccache. 

CCache is a compiler cache. Whenever the compiler is run, ccache hashes all input files, together with the compiler flags. It then checks if it's cache already contains an entry for the hash value. If this is not the case, ccache runs the compiler and stores the output together with the hash value of the input in it's cache. If the hash value is present already, it does not run the compiler but uses the compiler output stored in it's cache. This considerably speeds up recompilations.

But ccache still has to build the hash values and copy the compiler output, which takes some time. This is where tracking the build dependencies comes in. The following parameters can change between measurements:
\begin{description}
\item[Macro definitions]
Each macro definition is stored in a separate file, which is only updated by the measurement driver if the macro definition changes. Every source file which needs a macro definition includes the corresponding file. These inclusions are tracked and allow to only recompile the affected source files.
\item[Compiler flags] 
Only the measurer, measurement scheme and kernel need to be compiled using the compiler flags specified by the measurement. The compiler flags used for the rest of the measuring core do not affect the measurement results. The compiler flags are stored in a separate file. Whenever it is changed, the parts affected are recompiled.
\item[Combination of measurer, measurement scheme and kernel]
The measurement scheme has template parameters for the kernel and the measurer. The measurement driver stores the template instantiation used for a specific measurement in a separate file, which is recompiled whenever it is changed.
\end{description}

\file{measuringCore/makefile}
The build process is controlled using the gnu make utility \cite{make}. Make automatically determines which parts of a program have to be recompiled, based on rules stored in a makefile. Each rule consists of target files, prerequisite files and a recipe. Make checks the modification times of the target and the prerequisite files. If any prerequisite is newer than any target, the recipe is executed in order to update the traget files. The recipe is a sequence of shell commands.

The makefile used for the measuring core first instructs make to use the find utility to get a list of all source files (with .cpp extension) in the measuringCore/src and measuringCore/generated directories.

The list of all source files is split into the kernel sources and the normal sources. The kernel sources are the source files which are to be compiled using the optimization flags specific to the current measurement. The optimization flags for the normal source files do not depend on the measurement, and thus do not need to be recompiled when the optimization flags for the measurement change.

Since every measurement requires exactly one kernel, not all kernels need to be built for every measurement. This is reflected in the makefile removing all files from the kernel sources but the MeasurementSchemeRegistration, the source file for the current kernel and all source files in a subdirectory named after the current kernel.

From the normal sources and the kernel sources, the file names of the object files in the build directory are generated. The measuring core executable depends on these object files. Pattern rules are used to trigger the compile the source files into the object files.

There is a rule without recipe with the kernel objects as target and the file containing the measurement specific optimization flags as prerequisite. This causes the file containing the optimization flags to be added as prerequisite for each kernel object file.

In the C programming language, it is possible to include other files in a source file. Of course, the compilated code depends on the contents of the included files, too. To track these build dependencies, the compiler is instructed to generate rules without recipes with the object file as target and the source file together with the included files as prerequisites. The generated rules are stored in .d files in the build directory and are included in the makefile.

If special compilation flags are required for a source file, a rule should be added near the end of the makefile.

\subsubsection{System Initialization}
We chose a modular approach to initialize the measuring core. Whenever a system part needs to run code when the program starts or shuts down, it can instantiate a class derived from SystemInitializer.
\file{measuringCore/baseClasses/SystemInitializer.h}
This is preferably archieved by declaring a global static variable named dummy in a .cpp file. Example:
\begin{verbatim}
// define and register a system initializer.
static class Initializer: public SystemInitializer{
  void start(){
    // code to be executed on startup
  }

  void stop(){
    // code to be executed on shutdown
  }
} dummy;
\end{verbatim}

Whenever a SystemInitializer is instantiated, the instance is registered in a static global list. On system startup and shutdown, the start() respective stop() method of all registered SystemInitializers is called.

\subsubsection{Type Registry}
The Measuring Core receives kernel, measurement scheme and measurer descriptions and needs to instantiate the corresponding kernels, measurement schemes and measurers. Conceptually, each description class is associated to exactly one object class. The description describes instances of the associated object class. In code, the realtionships are represented using typedefs and they are checked using concept checking (\cite{siek01_concept_check}).

The object classes are grouped by base classes. The TypeRegistry templated class is instantiated for each base class. For each object class a TypeRegisterer is instantiated as static global variable (static means only visible in the file that defines the variable). The constructor of the TypeRegisterer creates a TypeRegistryEntry for the object class and adds it to the corresponding TypeRegistry instantiation.

\umlDiagram{TypeRegistry}

The MeasurerScheme has template type parameters for the measurer and the kernel it operates on. This allows the compiler to do optimizations, which is important for small kernels. The type registry supports this by accepting a number of arguments along with the description. The arguments sent to the TypeRegistryEntries for matching. The matching is based on the dynamic type of the provided arguments and the TArgs type arguments of the TypeRegistryEntry. When creating an object, the arguments are passed to the object constructor.

The methods on the TypeRegistry have type arguments. These will be set to the base classes of the arguments. But the important information is the actual type of the arguments. Therefore the arguments are packed into a vector and sent to the TypeRegistryEntries which use dynamic\_cast to determine if the arguments match the type arguments. Dynamic cast needs pointers to a polymorphic class. Since void pointers are not polymorphic, pointers to PolymorphicBase are used.

The code makes use of variadic templates (\cite{Gregor06:variadics_rev_3}).

\section{Measuring Execution Time}
\begin{itemize}
\item 0x40000000   UNHALTED\_CORE\_CYCLES 30Ah CPU\_CLK\_UNHALTED.CORE
\item 0x40000025   UNHALTED\_REFERENCE\_CYCLES 30Bh CPU\_CLK\_UNHALTED.REF
\item 0x400000ad   THERMAL\_TRIP 3Bh C0h 
\item 0x400000ae   CPU\_CLK\_UNHALTED
\item 0x400001a9   ix86arch::UNHALTED\_CORE\_CYCLES
\item 0x400001aa   ix86arch::INSTRUCTION\_RETIRED
\item 0x400001ab   ix86arch::UNHALTED\_REFERENCE\_CYCLES 
\end{itemize}
\subsection{Frequency Scaling}
The core frequency is not constant in current processors. Since the memory latencies and throughputs do not scale with the core freqency, a lower core freqency will generally cause a higher percentage of the peak performance to be reached by the kernel.

It is difficult to control the core frequency. But the frequency should at least be recorded along with the measurement. If the frequency changes during the measurement, this should be recored as well. The other option is to disable frequency scaling completely.

\section{Measuring Memory Traffic}
\begin{itemize}
\item 0x40000027   LLC\_MISSES
\item 0x40000040   SSE\_PRE\_EXEC 07h03h SSE\_PRE\_EXEC.L2
\item 0x40000059   L2\_DBUS\_BUSY\_RD
\item 0x4000005c   L2\_LINES\_IN  24h
\item 0x4000006a   L2\_M\_LINES\_OUT  27h
\item 0x400000cb   SSE\_PRE\_MISS 4Bh 00h/01h/02h
\item 62h BUS\_DRDY\_CLOCKS
\end{itemize}


\section{Mesuring Operation Count}
\begin{itemize}
\item 0x40000156   SIMD\_UOP\_TYPE\_EXEC B3h 01h/20h
\end{itemize}


\listoffigures

\bibliographystyle{abbrv}
\bibliography{../report.bib}

\printindex{referencedFiles}{Referenced Files}

\end{document}
